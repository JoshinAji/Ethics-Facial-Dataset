{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9d8da1e",
   "metadata": {},
   "source": [
    "# Robust Subset Builder (FairFace/UTKFace)\n",
    "_Auto-generated on 2025-11-08 05:53:19_\n",
    "\n",
    "This notebook builds a stratified subset of size `TARGET_TOTAL` from a combined pool (`data/pool.csv`) with a target source split (e.g., 60% FairFace / 40% UTKFace). It allocates per-race quotas, handles source availability, tops-up if needed, and freezes train/val/test splits stratified by race."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f941cb",
   "metadata": {},
   "source": [
    "## Imports & Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c25655",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TARGET_TOTAL = 900\n",
    "FAIRFACE_RATIO = 0.60     # 60/40 split FairFace/UTKFace\n",
    "SEED = 42\n",
    "\n",
    "# Races you care about (adjust if needed)\n",
    "RACES = ['White','Black','EastAsian','SouthAsian','SoutheastAsian','MiddleEastern','Latino']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d881950",
   "metadata": {},
   "source": [
    "## 1) Load pool and filter races"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88398fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = pd.read_csv('data/pool.csv')\n",
    "pool = pool[pool['race_cat'].isin(RACES)].copy()\n",
    "\n",
    "# Sanity: image_id uniqueness\n",
    "assert pool['image_id'].is_unique, 'image_id not unique; check pool building.'\n",
    "print('Pool shape after race filter:', pool.shape)\n",
    "pool.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baad9e04",
   "metadata": {},
   "source": [
    "## 2) Decide per-source totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c93081",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ff  = int(TARGET_TOTAL * FAIRFACE_RATIO)\n",
    "N_utk = TARGET_TOTAL - N_ff\n",
    "print('Target totals → FairFace:', N_ff, '| UTKFace:', N_utk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a366eef",
   "metadata": {},
   "source": [
    "## 3) Per-race quotas and availability by source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43a5bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equal quota per race, distribute any remainder deterministically by order\n",
    "per_race_total = {r: TARGET_TOTAL // len(RACES) for r in RACES}\n",
    "remainder = TARGET_TOTAL - sum(per_race_total.values())\n",
    "for r in RACES[:remainder]:\n",
    "    per_race_total[r] += 1\n",
    "print('Per-race totals:', per_race_total)\n",
    "\n",
    "counts_by_source = pool.groupby(['source_dataset','race_cat']).size().unstack(fill_value=0)\n",
    "display(counts_by_source)\n",
    "\n",
    "# Races that have no UTKFace availability\n",
    "ff_only = [r for r in RACES if counts_by_source.get(r, pd.Series()).get('UTKFace', 0) == 0]\n",
    "print('FF-only races (no UTK availability):', ff_only)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abeb18d",
   "metadata": {},
   "source": [
    "## 4) Split per-race quota into per-source quotas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7099269",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_race_ff  = {}\n",
    "per_race_utk = {}\n",
    "for r in RACES:\n",
    "    t = per_race_total[r]\n",
    "    if r in ff_only:\n",
    "        per_race_ff[r]  = min(t, counts_by_source.get(r, pd.Series()).get('FairFace', 0))\n",
    "        per_race_utk[r] = 0\n",
    "    else:\n",
    "        ff_avail  = counts_by_source.get(r, pd.Series()).get('FairFace', 0)\n",
    "        utk_avail = counts_by_source.get(r, pd.Series()).get('UTKFace', 0)\n",
    "        ff_q = min(int(round(t * FAIRFACE_RATIO)), ff_avail)\n",
    "        utk_q = min(t - ff_q, utk_avail)\n",
    "        if ff_q + utk_q < t:\n",
    "            deficit = t - (ff_q + utk_q)\n",
    "            ff_room  = ff_avail  - ff_q\n",
    "            utk_room = utk_avail - utk_q\n",
    "            take_ff  = min(deficit, max(ff_room, 0))\n",
    "            ff_q    += take_ff\n",
    "            deficit -= take_ff\n",
    "            if deficit > 0:\n",
    "                utk_q += min(deficit, max(utk_room, 0))\n",
    "        per_race_ff[r], per_race_utk[r] = ff_q, utk_q\n",
    "\n",
    "print('Per-race FairFace quotas:', per_race_ff)\n",
    "print('Per-race UTKFace quotas:', per_race_utk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971b5956",
   "metadata": {},
   "source": [
    "## 5) Initial per-race sampling by source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24eab48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(SEED)\n",
    "\n",
    "def sample_quota(df, n):\n",
    "    n = max(0, int(n))\n",
    "    if len(df) <= n:\n",
    "        return df.copy()\n",
    "    return df.sample(n=n, random_state=SEED)\n",
    "\n",
    "picked_ff  = []\n",
    "picked_utk = []\n",
    "for r in RACES:\n",
    "    df_ff  = pool[(pool.source_dataset=='FairFace') & (pool.race_cat==r)]\n",
    "    df_utk = pool[(pool.source_dataset=='UTKFace') & (pool.race_cat==r)]\n",
    "    picked_ff.append(sample_quota(df_ff,  per_race_ff[r]))\n",
    "    picked_utk.append(sample_quota(df_utk, per_race_utk[r]))\n",
    "\n",
    "subset = pd.concat(picked_ff + picked_utk, ignore_index=True).drop_duplicates('image_id')\n",
    "print('Subset after initial sampling:', subset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e5dcc1",
   "metadata": {},
   "source": [
    "## 6) Top-up if short overall or per-source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d082869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_up(source_name, need, already):\n",
    "    if need <= 0:\n",
    "        return pd.DataFrame(columns=already.columns)\n",
    "    pool_src = pool[pool.source_dataset==source_name]\n",
    "    # Avoid items already in subset by image_id\n",
    "    pool_src = pool_src[~pool_src['image_id'].isin(already.index)]\n",
    "    pool_src = pool_src.sample(frac=1.0, random_state=SEED)  # shuffle\n",
    "    take = min(need, len(pool_src))\n",
    "    return pool_src.iloc[:take].copy()\n",
    "\n",
    "def count_source(df, name):\n",
    "    return (df.source_dataset==name).sum()\n",
    "\n",
    "N_ff  = int(TARGET_TOTAL * FAIRFACE_RATIO)\n",
    "N_utk = TARGET_TOTAL - N_ff\n",
    "\n",
    "need_ff  = N_ff  - count_source(subset, 'FairFace')\n",
    "need_utk = N_utk - count_source(subset, 'UTKFace')\n",
    "\n",
    "if need_ff > 0:\n",
    "    subset = pd.concat([\n",
    "        subset,\n",
    "        top_up('FairFace', need_ff, subset.set_index('image_id'))\n",
    "    ], ignore_index=True).drop_duplicates('image_id')\n",
    "\n",
    "if need_utk > 0:\n",
    "    subset = pd.concat([\n",
    "        subset,\n",
    "        top_up('UTKFace', need_utk, subset.set_index('image_id'))\n",
    "    ], ignore_index=True).drop_duplicates('image_id')\n",
    "\n",
    "# Fill to TARGET_TOTAL if still short\n",
    "still_short = TARGET_TOTAL - len(subset)\n",
    "if still_short > 0:\n",
    "    remain = pool[~pool['image_id'].isin(subset['image_id'])]\n",
    "    fill = remain.sample(min(still_short, len(remain)), random_state=SEED)\n",
    "    subset = pd.concat([subset, fill], ignore_index=True).drop_duplicates('image_id')\n",
    "\n",
    "# Trim if overshot\n",
    "if len(subset) > TARGET_TOTAL:\n",
    "    subset = subset.sample(n=TARGET_TOTAL, random_state=SEED)\n",
    "\n",
    "def count_source(df, name): return (df.source_dataset==name).sum()\n",
    "ff_ct  = count_source(subset, 'FairFace')\n",
    "utk_ct = count_source(subset, 'UTKFace')\n",
    "print(f'✅ Subset size: {len(subset)}  | FairFace: {ff_ct}  | UTKFace: {utk_ct}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b17122b",
   "metadata": {},
   "source": [
    "## 7) Train/Val/Test stratified split (by race) and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3ce58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, temp = train_test_split(subset, test_size=0.30, random_state=SEED, stratify=subset['race_cat'])\n",
    "val,   test = train_test_split(temp,   test_size=0.50, random_state=SEED, stratify=temp['race_cat'])\n",
    "\n",
    "def tag(df, name):\n",
    "    df=df.copy(); df['split']=name; return df\n",
    "\n",
    "master = pd.concat([tag(train,'train'), tag(val,'val'), tag(test,'test')], ignore_index=True)\n",
    "out_path = 'data/splits/master.csv'\n",
    "master.to_csv(out_path, index=False)\n",
    "print('✅', out_path, 'written.')\n",
    "master.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fdf65d",
   "metadata": {},
   "source": [
    "## 8) Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814f470c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nCounts by source in master:')\n",
    "print(master['source_dataset'].value_counts())\n",
    "\n",
    "print('\\nCounts by race in master:')\n",
    "print(master['race_cat'].value_counts())\n",
    "\n",
    "print('\\nRace × Split counts:')\n",
    "print(master.pivot_table(index='race_cat', columns='split', values='image_id', aggfunc='count').fillna(0).astype(int))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
